{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os.path\n",
    "import time\n",
    "from collections import OrderedDict\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "\n",
    "import torch as th\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "\n",
    "from braindecode.models.deep4 import Deep4Net\n",
    "from braindecode.datasets.bcic_iv_2a import BCICompetition4Set2A\n",
    "from braindecode.experiments.experiment import Experiment\n",
    "from braindecode.experiments.monitors import LossMonitor, MisclassMonitor, \\\n",
    "    RuntimeMonitor\n",
    "from braindecode.experiments.stopcriteria import MaxEpochs, NoDecrease, Or\n",
    "from braindecode.datautil.iterators import BalancedBatchSizeIterator\n",
    "from braindecode.models.shallow_fbcsp import ShallowFBCSPNet\n",
    "from braindecode.datautil.splitters import split_into_two_sets\n",
    "from braindecode.torch_ext.constraints import MaxNormDefaultConstraint\n",
    "from braindecode.torch_ext.util import set_random_seeds, np_to_var\n",
    "from braindecode.mne_ext.signalproc import mne_apply\n",
    "from braindecode.datautil.signalproc import (bandpass_cnt,\n",
    "                                             exponential_running_standardize)\n",
    "from braindecode.datautil.trial_segment import create_signal_target_from_raw_mne\n",
    "\n",
    "log = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Shallow Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(asctime)s %(levelname)s : %(message)s',\n",
    "                    level=logging.DEBUG, stream=sys.stdout)\n",
    "# Should contain both .gdf files and .mat-labelfiles from competition\n",
    "data_folder = '/home/david/data/BCICIV_2a_gdf/'\n",
    "subject_id = 1 # 1-9\n",
    "low_cut_hz = 4 # 0 or 4\n",
    "model = 'shallow' #'shallow' or 'deep'\n",
    "cuda = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from /home/david/data/BCICIV_2a_gdf/A01T.gdf...\n",
      "GDF file detected\n",
      "Overlapping events detected. Use find_edf_events for the original events.\n",
      "Setting channel info structure...\n",
      "Interpolating stim channel. Events may jitter.\n",
      "Creating raw.info structure...\n",
      "Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "Reading 0 ... 672527  =      0.000 ...  2690.108 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/anaconda3/envs/machinelearning/lib/python3.6/site-packages/mne/io/edf/edf.py:1028: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  etmode = np.fromstring(etmode, np.uint8).tolist()[0]\n",
      "/home/david/anaconda3/envs/machinelearning/lib/python3.6/site-packages/braindecode/datasets/bcic_iv_2a.py:20: RuntimeWarning: Overlapping events detected. Use find_edf_events for the original events.\n",
      "  raw_edf = mne.io.read_raw_edf(self.filename, stim_channel='auto')\n",
      "/home/david/anaconda3/envs/machinelearning/lib/python3.6/site-packages/braindecode/datasets/bcic_iv_2a.py:20: RuntimeWarning: Interpolating stim channel. Events may jitter.\n",
      "  raw_edf = mne.io.read_raw_edf(self.filename, stim_channel='auto')\n",
      "/home/david/anaconda3/envs/machinelearning/lib/python3.6/site-packages/braindecode/datasets/bcic_iv_2a.py:20: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  raw_edf = mne.io.read_raw_edf(self.filename, stim_channel='auto')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from /home/david/data/BCICIV_2a_gdf/A01E.gdf...\n",
      "GDF file detected\n",
      "Overlapping events detected. Use find_edf_events for the original events.\n",
      "Setting channel info structure...\n",
      "Interpolating stim channel. Events may jitter.\n",
      "Creating raw.info structure...\n",
      "Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "Reading 0 ... 686999  =      0.000 ...  2747.996 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/anaconda3/envs/machinelearning/lib/python3.6/site-packages/mne/io/edf/edf.py:1028: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  etmode = np.fromstring(etmode, np.uint8).tolist()[0]\n",
      "/home/david/anaconda3/envs/machinelearning/lib/python3.6/site-packages/braindecode/datasets/bcic_iv_2a.py:20: RuntimeWarning: Overlapping events detected. Use find_edf_events for the original events.\n",
      "  raw_edf = mne.io.read_raw_edf(self.filename, stim_channel='auto')\n",
      "/home/david/anaconda3/envs/machinelearning/lib/python3.6/site-packages/braindecode/datasets/bcic_iv_2a.py:20: RuntimeWarning: Interpolating stim channel. Events may jitter.\n",
      "  raw_edf = mne.io.read_raw_edf(self.filename, stim_channel='auto')\n",
      "/home/david/anaconda3/envs/machinelearning/lib/python3.6/site-packages/braindecode/datasets/bcic_iv_2a.py:20: RuntimeWarning: Channel names are not unique, found duplicates for: {'EEG'}. Applying running numbers for duplicates.\n",
      "  raw_edf = mne.io.read_raw_edf(self.filename, stim_channel='auto')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-10-01 16:47:55,295 INFO : Trial per class:\n",
      "Counter({'Tongue': 72, 'Foot': 72, 'Right Hand': 72, 'Left Hand': 72})\n",
      "2018-10-01 16:47:55,527 INFO : Trial per class:\n",
      "Counter({'Left Hand': 72, 'Right Hand': 72, 'Foot': 72, 'Tongue': 72})\n"
     ]
    }
   ],
   "source": [
    "ival = [-500, 4000]\n",
    "max_epochs = 1600\n",
    "max_increase_epochs = 160\n",
    "batch_size = 60\n",
    "high_cut_hz = 38\n",
    "factor_new = 1e-3\n",
    "init_block_size = 1000\n",
    "valid_set_fraction = 0.2\n",
    "\n",
    "train_filename = 'A{:02d}T.gdf'.format(subject_id)\n",
    "test_filename = 'A{:02d}E.gdf'.format(subject_id)\n",
    "train_filepath = os.path.join(data_folder, train_filename)\n",
    "test_filepath = os.path.join(data_folder, test_filename)\n",
    "train_label_filepath = train_filepath.replace('.gdf', '.mat')\n",
    "test_label_filepath = test_filepath.replace('.gdf', '.mat')\n",
    "\n",
    "train_loader = BCICompetition4Set2A(\n",
    "    train_filepath, labels_filename=train_label_filepath)\n",
    "test_loader = BCICompetition4Set2A(\n",
    "    test_filepath, labels_filename=test_label_filepath)\n",
    "train_cnt = train_loader.load()\n",
    "test_cnt = test_loader.load()\n",
    "\n",
    "# Preprocessing\n",
    "\n",
    "train_cnt = train_cnt.drop_channels(['STI 014', 'EOG-left',\n",
    "                                     'EOG-central', 'EOG-right'])\n",
    "assert len(train_cnt.ch_names) == 22\n",
    "# lets convert to millvolt for numerical stability of next operations\n",
    "train_cnt = mne_apply(lambda a: a * 1e6, train_cnt)\n",
    "train_cnt = mne_apply(\n",
    "    lambda a: bandpass_cnt(a, low_cut_hz, high_cut_hz, train_cnt.info['sfreq'],\n",
    "                           filt_order=3,\n",
    "                           axis=1), train_cnt)\n",
    "train_cnt = mne_apply(\n",
    "    lambda a: exponential_running_standardize(a.T, factor_new=factor_new,\n",
    "                                              init_block_size=init_block_size,\n",
    "                                              eps=1e-4).T,\n",
    "    train_cnt)\n",
    "\n",
    "test_cnt = test_cnt.drop_channels(['STI 014', 'EOG-left',\n",
    "                                   'EOG-central', 'EOG-right'])\n",
    "assert len(test_cnt.ch_names) == 22\n",
    "test_cnt = mne_apply(lambda a: a * 1e6, test_cnt)\n",
    "test_cnt = mne_apply(\n",
    "    lambda a: bandpass_cnt(a, low_cut_hz, high_cut_hz, test_cnt.info['sfreq'],\n",
    "                           filt_order=3,\n",
    "                           axis=1), test_cnt)\n",
    "test_cnt = mne_apply(\n",
    "    lambda a: exponential_running_standardize(a.T, factor_new=factor_new,\n",
    "                                              init_block_size=init_block_size,\n",
    "                                              eps=1e-4).T,\n",
    "    test_cnt)\n",
    "\n",
    "marker_def = OrderedDict([('Left Hand', [1]), ('Right Hand', [2],),\n",
    "                          ('Foot', [3]), ('Tongue', [4])])\n",
    "\n",
    "train_set = create_signal_target_from_raw_mne(train_cnt, marker_def, ival)\n",
    "test_set = create_signal_target_from_raw_mne(test_cnt, marker_def, ival)\n",
    "\n",
    "train_set, valid_set = split_into_two_sets(\n",
    "    train_set, first_set_fraction=1-valid_set_fraction)\n",
    "\n",
    "set_random_seeds(seed=20190706, cuda=cuda)\n",
    "\n",
    "n_classes = 4\n",
    "n_chans = int(train_set.X.shape[1])\n",
    "input_time_length = train_set.X.shape[2]\n",
    "if model == 'shallow':\n",
    "    model = ShallowFBCSPNet(n_chans, n_classes, input_time_length=input_time_length,\n",
    "                        final_conv_length='auto').create_network()\n",
    "elif model == 'deep':\n",
    "    model = Deep4Net(n_chans, n_classes, input_time_length=input_time_length,\n",
    "                        final_conv_length='auto').create_network()\n",
    "if cuda:\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(230, 22, 1125)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(288, 22, 1125)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set.X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-10-01 16:47:57,184 INFO : Model: \n",
      "Sequential(\n",
      "  (dimshuffle): Expression(expression=_transpose_time_to_spat)\n",
      "  (conv_time): Conv2d (1, 40, kernel_size=(25, 1), stride=(1, 1))\n",
      "  (conv_spat): Conv2d (40, 40, kernel_size=(1, 22), stride=(1, 1), bias=False)\n",
      "  (bnorm): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (conv_nonlin): Expression(expression=square)\n",
      "  (pool): AvgPool2d(kernel_size=(75, 1), stride=(15, 1), padding=0, ceil_mode=False, count_include_pad=True)\n",
      "  (pool_nonlin): Expression(expression=safe_log)\n",
      "  (drop): Dropout(p=0.5)\n",
      "  (conv_classifier): Conv2d (40, 4, kernel_size=(69, 1), stride=(1, 1))\n",
      "  (softmax): LogSoftmax()\n",
      "  (squeeze): Expression(expression=_squeeze_final_output)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "log.info(\"Model: \\n{:s}\".format(str(model)))\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "iterator = BalancedBatchSizeIterator(batch_size=batch_size)\n",
    "\n",
    "stop_criterion = Or([MaxEpochs(max_epochs),\n",
    "                     NoDecrease('valid_misclass', max_increase_epochs)])\n",
    "\n",
    "monitors = [LossMonitor(), MisclassMonitor(), RuntimeMonitor()]\n",
    "\n",
    "model_constraint = MaxNormDefaultConstraint()\n",
    "\n",
    "exp = Experiment(model, train_set, valid_set, test_set, iterator=iterator,\n",
    "                 loss_function=F.nll_loss, optimizer=optimizer,\n",
    "                 model_constraint=model_constraint,\n",
    "                 monitors=monitors,\n",
    "                 stop_criterion=stop_criterion,\n",
    "                 remember_best_column='valid_misclass',\n",
    "                 run_after_early_stop=True, cuda=cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test feature_vars shape\n",
      "(288, 22, 1125)\n"
     ]
    }
   ],
   "source": [
    "print(\"test feature_vars shape\")\n",
    "print(exp.datasets['test'].X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test target_vars\n",
      "[0 1 1 0 1 0 1 2 1 3 0 2 1 0 3 3 3 3 3 0 2 1 0 0 2 3 0 2 2 2 0 1 0 1 1 0 1\n",
      " 2 1 2 2 3 2 2 3 3 3 3 3 2 1 0 0 1 2 3 1 2 0 0 0 3 1 1 0 0 2 0 1 3 3 2 0 3\n",
      " 3 1 3 3 1 0 1 2 2 2 3 2 0 3 1 2 1 2 3 1 2 0 0 0 3 1 0 2 0 2 1 3 0 2 2 0 2\n",
      " 1 3 3 3 2 0 3 1 3 1 0 2 1 0 2 2 0 2 3 3 1 0 1 3 1 3 2 1 1 1 2 3 0 1 3 0 2\n",
      " 2 3 0 0 2 1 3 3 3 1 0 2 1 3 0 3 2 1 3 3 0 1 1 2 3 1 0 0 3 1 0 2 1 1 2 0 3\n",
      " 2 2 2 2 0 1 0 1 0 0 2 2 1 2 3 0 3 0 0 1 3 2 1 3 2 3 2 3 1 1 3 0 1 1 1 2 3\n",
      " 0 3 0 2 0 3 0 2 0 1 2 2 3 0 1 3 1 2 2 0 3 1 3 0 0 2 2 1 3 1 1 0 1 3 3 1 1\n",
      " 1 1 3 3 2 3 0 1 2 1 0 3 0 3 0 0 0 0 2 2 3 1 2 2 2 3 2 0 2]\n"
     ]
    }
   ],
   "source": [
    "print(\"test target_vars\")\n",
    "print(exp.datasets['test'].y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test target_vars shape: (288,)\n"
     ]
    }
   ],
   "source": [
    "print(\"test target_vars shape:\", exp.datasets['test'].y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_vars shape: (58, 22, 1125, 1)\n",
      "target_vars shape: (58,)\n",
      "feature_vars shape: (58, 22, 1125, 1)\n",
      "target_vars shape: (58,)\n",
      "feature_vars shape: (58, 22, 1125, 1)\n",
      "target_vars shape: (58,)\n",
      "feature_vars shape: (57, 22, 1125, 1)\n",
      "target_vars shape: (57,)\n",
      "feature_vars shape: (57, 22, 1125, 1)\n",
      "target_vars shape: (57,)\n"
     ]
    }
   ],
   "source": [
    "all_actual = []\n",
    "dataset = 'test'\n",
    "for inputs, targets in exp.iterator.get_batches(exp.datasets[dataset], shuffle=False):\n",
    "\n",
    "    print(\"feature_vars shape:\", np.array(inputs).shape)\n",
    "    print(\"target_vars shape:\", np.array(targets).shape)\n",
    "    \n",
    "    feature_vars = np_to_var(inputs, pin_memory = exp.pin_memory, volatile=True)\n",
    "    target_vars = np_to_var(targets, pin_memory = exp.pin_memory, volatile=True)\n",
    "\n",
    "    if exp.cuda:\n",
    "        feature_vars = feature_vars.cuda()\n",
    "        target_vars = target_vars.cuda()\n",
    "\n",
    "    if hasattr(target_vars, 'cpu'):\n",
    "        target_vars = target_vars.cpu().data.numpy()\n",
    "    else:\n",
    "        # assume it is iterable\n",
    "        target_vars = [o.cpu().data.numpy() for o in target_vars]\n",
    "    \n",
    "    all_actual += target_vars.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 1, 0, 1, 2, 1, 3, 0, 2, 1, 0, 3, 3, 3, 3, 3, 0, 2, 1,\n",
       "       0, 0, 2, 3, 0, 2, 2, 2, 0, 1, 0, 1, 1, 0, 1, 2, 1, 2, 2, 3, 2, 2,\n",
       "       3, 3, 3, 3, 3, 2, 1, 0, 0, 1, 2, 3, 1, 2, 0, 0, 0, 3, 1, 1, 0, 0,\n",
       "       2, 0, 1, 3, 3, 2, 0, 3, 3, 1, 3, 3, 1, 0, 1, 2, 2, 2, 3, 2, 0, 3,\n",
       "       1, 2, 1, 2, 3, 1, 2, 0, 0, 0, 3, 1, 0, 2, 0, 2, 1, 3, 0, 2, 2, 0,\n",
       "       2, 1, 3, 3, 3, 2, 0, 3, 1, 3, 1, 0, 2, 1, 0, 2, 2, 0, 2, 3, 3, 1,\n",
       "       0, 1, 3, 1, 3, 2, 1, 1, 1, 2, 3, 0, 1, 3, 0, 2, 2, 3, 0, 0, 2, 1,\n",
       "       3, 3, 3, 1, 0, 2, 1, 3, 0, 3, 2, 1, 3, 3, 0, 1, 1, 2, 3, 1, 0, 0,\n",
       "       3, 1, 0, 2, 1, 1, 2, 0, 3, 2, 2, 2, 2, 0, 1, 0, 1, 0, 0, 2, 2, 1,\n",
       "       2, 3, 0, 3, 0, 0, 1, 3, 2, 1, 3, 2, 3, 2, 3, 1, 1, 3, 0, 1, 1, 1,\n",
       "       2, 3, 0, 3, 0, 2, 0, 3, 0, 2, 0, 1, 2, 2, 3, 0, 1, 3, 1, 2, 2, 0,\n",
       "       3, 1, 3, 0, 0, 2, 2, 1, 3, 1, 1, 0, 1, 3, 3, 1, 1, 1, 1, 3, 3, 2,\n",
       "       3, 0, 1, 2, 1, 0, 3, 0, 3, 0, 0, 0, 0, 2, 2, 3, 1, 2, 2, 2, 3, 2,\n",
       "       0, 2])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(all_actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(288,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(all_actual).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
